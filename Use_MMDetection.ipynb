{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Use_MMDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/saotomryo/Use_MMDetection/blob/main/Use_MMDetection.ipynb",
      "authorship_tag": "ABX9TyOuJ94fBXMvsWxHScM4AS+J",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saotomryo/Use_MMDetection/blob/main/Use_MMDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IPmHECyfHPp",
        "outputId": "3eefe22a-9960-4956-b4cf-f4518d8fc24d"
      },
      "source": [
        "import torch\n",
        "import json\n",
        "from skimage import measure\n",
        "import numpy as np\n",
        "print(torch.__version__)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"device = \", device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu111\n",
            "device =  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xdkNklHDWku"
      },
      "source": [
        "## 環境準備 MMCV MMDetectionのインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuhLiZC2ClOE",
        "outputId": "8f668f58-7308-4d48-f0a9-13ec20086cfa"
      },
      "source": [
        "# MMCVのインストール（30分程度かかります）\n",
        "\n",
        "!pip install mmcv-full==1.3.8"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mmcv-full==1.3.8\n",
            "  Downloading mmcv-full-1.3.8.tar.gz (312 kB)\n",
            "\u001b[K     |████████████████████████████████| 312 kB 8.3 MB/s \n",
            "\u001b[?25hCollecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.3.8) (1.19.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.3.8) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.3.8) (3.13)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.31.0-py2.py3-none-any.whl (185 kB)\n",
            "\u001b[K     |████████████████████████████████| 185 kB 45.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mmcv-full\n",
            "  Building wheel for mmcv-full (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmcv-full: filename=mmcv_full-1.3.8-cp37-cp37m-linux_x86_64.whl size=29531064 sha256=6e5012e48150237bf67ae58f2e809c7dbd86717a567adc958afca57ef6c2c254\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c4/8d/b5bab7347e1b71280505e58eca95d00a53a524a7d5fa3ac89f\n",
            "Successfully built mmcv-full\n",
            "Installing collected packages: yapf, addict, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.3.8 yapf-0.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3WNFcX3PUcP"
      },
      "source": [
        "HOME_PATH = \"/content\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKdRG66riHGN",
        "outputId": "7b40219f-d87a-4db3-f2d9-60ace23c274e"
      },
      "source": [
        "\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "%cd mmdetection\n",
        "!pip install -r requirements/build.txt\n",
        "!pip install \"git+https://github.com/open-mmlab/cocoapi.git#subdirectory=pycocotools\"\n",
        "!pip install -v -e .  # or \"python setup.py develop\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mmdetection'...\n",
            "remote: Enumerating objects: 21477, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 21477 (delta 5), reused 5 (delta 0), pack-reused 21454\u001b[K\n",
            "Receiving objects: 100% (21477/21477), 25.04 MiB | 25.92 MiB/s, done.\n",
            "Resolving deltas: 100% (15062/15062), done.\n",
            "/content/mmdetection\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r requirements/build.txt (line 2)) (0.29.24)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements/build.txt (line 3)) (1.19.5)\n",
            "Collecting git+https://github.com/open-mmlab/cocoapi.git#subdirectory=pycocotools\n",
            "  Cloning https://github.com/open-mmlab/cocoapi.git to /tmp/pip-req-build-gftcm9_a\n",
            "  Running command git clone -q https://github.com/open-mmlab/cocoapi.git /tmp/pip-req-build-gftcm9_a\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from mmpycocotools==12.0.3) (57.4.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from mmpycocotools==12.0.3) (0.29.24)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from mmpycocotools==12.0.3) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->mmpycocotools==12.0.3) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->mmpycocotools==12.0.3) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->mmpycocotools==12.0.3) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->mmpycocotools==12.0.3) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->mmpycocotools==12.0.3) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->mmpycocotools==12.0.3) (1.15.0)\n",
            "Building wheels for collected packages: mmpycocotools\n",
            "  Building wheel for mmpycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmpycocotools: filename=mmpycocotools-12.0.3-cp37-cp37m-linux_x86_64.whl size=264251 sha256=8be12ea1f77a736ed4bf2f8c469af4dae2b85d507d37635d7127bec77005d5b4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n0ehthhf/wheels/d4/38/2b/ec4e44ec87a2b8692cd999bb33a831823b8071d0f89661297e\n",
            "Successfully built mmpycocotools\n",
            "Installing collected packages: mmpycocotools\n",
            "Successfully installed mmpycocotools-12.0.3\n",
            "Using pip 21.1.3 from /usr/local/lib/python3.7/dist-packages/pip (python 3.7)\n",
            "Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/include/python3.7/UNKNOWN\n",
            "sysconfig: /usr/include/python3.7m/UNKNOWN\n",
            "Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/bin\n",
            "sysconfig: /usr/bin\n",
            "Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local\n",
            "sysconfig: /usr\n",
            "Additional context:\n",
            "user = False\n",
            "home = None\n",
            "root = None\n",
            "prefix = None\n",
            "Non-user install because site-packages writeable\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-a1hqwiys\n",
            "Created temporary directory: /tmp/pip-req-tracker-7p_8xobk\n",
            "Initialized build tracking at /tmp/pip-req-tracker-7p_8xobk\n",
            "Created build tracker: /tmp/pip-req-tracker-7p_8xobk\n",
            "Entered build tracker: /tmp/pip-req-tracker-7p_8xobk\n",
            "Created temporary directory: /tmp/pip-install-2fcgn01v\n",
            "Obtaining file:///content/mmdetection\n",
            "  Added file:///content/mmdetection to build tracker '/tmp/pip-req-tracker-7p_8xobk'\n",
            "    Running setup.py (path:/content/mmdetection/setup.py) egg_info for package from file:///content/mmdetection\n",
            "    Created temporary directory: /tmp/pip-pip-egg-info-d0rc9hqv\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-pip-egg-info-d0rc9hqv/mmdet.egg-info\n",
            "    writing /tmp/pip-pip-egg-info-d0rc9hqv/mmdet.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-pip-egg-info-d0rc9hqv/mmdet.egg-info/dependency_links.txt\n",
            "    writing requirements to /tmp/pip-pip-egg-info-d0rc9hqv/mmdet.egg-info/requires.txt\n",
            "    writing top-level names to /tmp/pip-pip-egg-info-d0rc9hqv/mmdet.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-d0rc9hqv/mmdet.egg-info/SOURCES.txt'\n",
            "    reading manifest template 'MANIFEST.in'\n",
            "    warning: no files found matching 'mmdet/VERSION'\n",
            "    warning: no files found matching 'mmdet/.mim/model-index.yml'\n",
            "    warning: no files found matching 'mmdet/.mim/demo/*/*'\n",
            "    warning: no files found matching '*.py' under directory 'mmdet/.mim/configs'\n",
            "    warning: no files found matching '*.yml' under directory 'mmdet/.mim/configs'\n",
            "    warning: no files found matching '*.sh' under directory 'mmdet/.mim/tools'\n",
            "    warning: no files found matching '*.py' under directory 'mmdet/.mim/tools'\n",
            "    adding license file 'LICENSE'\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-d0rc9hqv/mmdet.egg-info/SOURCES.txt'\n",
            "  Source in /content/mmdetection has version 2.17.0, which satisfies requirement mmdet==2.17.0 from file:///content/mmdetection\n",
            "  Removed mmdet==2.17.0 from file:///content/mmdetection from build tracker '/tmp/pip-req-tracker-7p_8xobk'\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmdet==2.17.0) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmdet==2.17.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmdet==2.17.0) (1.15.0)\n",
            "1 location(s) to search for versions of terminaltables:\n",
            "* https://pypi.org/simple/terminaltables/\n",
            "Fetching project page and analyzing links: https://pypi.org/simple/terminaltables/\n",
            "Getting page https://pypi.org/simple/terminaltables/\n",
            "Found index url https://pypi.org/simple\n",
            "Looking up \"https://pypi.org/simple/terminaltables/\" in the cache\n",
            "Request header has \"max_age\" as 0, cache bypassed\n",
            "Starting new HTTPS connection (1): pypi.org:443\n",
            "https://pypi.org:443 \"GET /simple/terminaltables/ HTTP/1.1\" 200 1231\n",
            "Updating cache with response from \"https://pypi.org/simple/terminaltables/\"\n",
            "Caching due to etag\n",
            "  Found link https://files.pythonhosted.org/packages/ec/82/6390ba7f110622d27b02451aaa294dc4b3133b7661e464db9a116e977324/terminaltables-1.0.0.tar.gz#sha256=4c909a5ee4a3d028b2c977d996f8b8cd9724ce8e4d9d834d65e78a98f7965b54 (from https://pypi.org/simple/terminaltables/), version: 1.0.0\n",
            "  Found link https://files.pythonhosted.org/packages/97/65/858bc3ea6cc60edc959ce427a94227932b5d9a95b0bce82f16071419885c/terminaltables-1.0.1.tar.gz#sha256=5548ac567d38d6ac88a5e0fec2d95f646249f37e1ef8fd2d17f8fcaefc6cf592 (from https://pypi.org/simple/terminaltables/), version: 1.0.1\n",
            "  Found link https://files.pythonhosted.org/packages/82/42/3f1140f6e538582fd514c765244662cca60885048cf610e7d00eaee8aeb1/terminaltables-1.0.2.tar.gz#sha256=cf97dd019af975cc64aa69aca435a43b0cffabb88df6f337c6b48de600c19f8e (from https://pypi.org/simple/terminaltables/), version: 1.0.2\n",
            "  Found link https://files.pythonhosted.org/packages/80/07/5663569dfd8fa4e4fa3cb645b70f4972e3d79d056b71da12df174668c145/terminaltables-1.1.0.tar.gz#sha256=94a15e1a295265d130de67e9c2efef9e1cad1e64dd6ae0b80882076581605f8c (from https://pypi.org/simple/terminaltables/), version: 1.1.0\n",
            "  Found link https://files.pythonhosted.org/packages/0c/4a/9b80642ac2463908fe77c9dbe138c56902fbf5a5a95d07203c131ec9ba90/terminaltables-1.1.1.tar.gz#sha256=b02c516d6d521ce0fe6e2a2753268e86547bbccab6bfa7e269a0f51766283fab (from https://pypi.org/simple/terminaltables/), version: 1.1.1\n",
            "  Found link https://files.pythonhosted.org/packages/a8/65/f9c6bcfb1f81acdfcd1f8d633c6752cfdcc04b5fade7638a2a8dc7a720de/terminaltables-1.2.0.tar.gz#sha256=fff4aa62f296038d1526a91856f0b3de1e3bce31cfd1c5148cc3f795c1d396bf (from https://pypi.org/simple/terminaltables/), version: 1.2.0\n",
            "  Found link https://files.pythonhosted.org/packages/3d/17/14aa6521b337be46c51dd7b31e7e617801e9f8db7f48583c767c02e0e72a/terminaltables-1.2.1.tar.gz#sha256=cf5f0fb6c6c3070d7af73537ded030858c122f253c87e7221f9a6da3782ce787 (from https://pypi.org/simple/terminaltables/), version: 1.2.1\n",
            "  Found link https://files.pythonhosted.org/packages/d0/8e/9403573ff8aebc09ee0aacd57885050f74bd9f48a85c0735d33cacfa2469/terminaltables-2.0.0.tar.gz#sha256=2e0a6688071f2a881f8fa4455a362457dcd2317e374609f1a09baffa998e7492 (from https://pypi.org/simple/terminaltables/), version: 2.0.0\n",
            "  Found link https://files.pythonhosted.org/packages/10/da/9bbb21c1c2f9be4df2056b00b569689b9ece538ef39bf8db34be25f9e850/terminaltables-2.1.0.tar.gz#sha256=33b60f027964214f4ff5821f43958d03add81784f7c183d86a7ee8f010350cf5 (from https://pypi.org/simple/terminaltables/), version: 2.1.0\n",
            "  Found link https://files.pythonhosted.org/packages/58/c9/f0c174c4e828365df3593c66ac32474cd994a8ec36fe19a798261c96c3bc/terminaltables-3.0.0.tar.gz#sha256=bd2504031f09f942a8f221266adc61aee04a0368d5de0dacb7a53e508af6a518 (from https://pypi.org/simple/terminaltables/), version: 3.0.0\n",
            "  Found link https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from https://pypi.org/simple/terminaltables/), version: 3.1.0\n",
            "Skipping link: not a file: https://pypi.org/simple/terminaltables/\n",
            "Given no hashes to check 11 links for project 'terminaltables': discarding no candidates\n",
            "Collecting terminaltables\n",
            "  Created temporary directory: /tmp/pip-unpack-msmaexwt\n",
            "  Looking up \"https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\" in the cache\n",
            "  No cache entry available\n",
            "  Starting new HTTPS connection (1): files.pythonhosted.org:443\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz HTTP/1.1\" 200 12478\n",
            "  Downloading terminaltables-3.1.0.tar.gz (12 kB)\n",
            "  Ignoring unknown cache-control directive: immutable\n",
            "  Updating cache with response from \"https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\"\n",
            "  Caching due to etag\n",
            "  Added terminaltables from https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from mmdet==2.17.0) to build tracker '/tmp/pip-req-tracker-7p_8xobk'\n",
            "    Running setup.py (path:/tmp/pip-install-2fcgn01v/terminaltables_70e1b348f2174c21a321e39b5e4627d1/setup.py) egg_info for package terminaltables\n",
            "    Created temporary directory: /tmp/pip-pip-egg-info-cylr447v\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-pip-egg-info-cylr447v/terminaltables.egg-info\n",
            "    writing /tmp/pip-pip-egg-info-cylr447v/terminaltables.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-pip-egg-info-cylr447v/terminaltables.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-pip-egg-info-cylr447v/terminaltables.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-cylr447v/terminaltables.egg-info/SOURCES.txt'\n",
            "    reading manifest file '/tmp/pip-pip-egg-info-cylr447v/terminaltables.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-cylr447v/terminaltables.egg-info/SOURCES.txt'\n",
            "  Source in /tmp/pip-install-2fcgn01v/terminaltables_70e1b348f2174c21a321e39b5e4627d1 has version 3.1.0, which satisfies requirement terminaltables from https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from mmdet==2.17.0)\n",
            "  Removed terminaltables from https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from mmdet==2.17.0) from build tracker '/tmp/pip-req-tracker-7p_8xobk'\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from mmdet==2.17.0) (2.0.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.17.0) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.17.0) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.17.0) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.17.0) (2.4.7)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools->mmdet==2.17.0) (0.29.24)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->mmdet==2.17.0) (57.4.0)\n",
            "Created temporary directory: /tmp/pip-unpack-8re9zz7w\n",
            "Building wheels for collected packages: terminaltables\n",
            "  Created temporary directory: /tmp/pip-wheel-0lfyi0fy\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-0lfyi0fy\n",
            "  Running command /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-2fcgn01v/terminaltables_70e1b348f2174c21a321e39b5e4627d1/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-2fcgn01v/terminaltables_70e1b348f2174c21a321e39b5e4627d1/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-0lfyi0fy\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib\n",
            "  creating build/lib/terminaltables\n",
            "  copying terminaltables/github_table.py -> build/lib/terminaltables\n",
            "  copying terminaltables/other_tables.py -> build/lib/terminaltables\n",
            "  copying terminaltables/terminal_io.py -> build/lib/terminaltables\n",
            "  copying terminaltables/__init__.py -> build/lib/terminaltables\n",
            "  copying terminaltables/ascii_table.py -> build/lib/terminaltables\n",
            "  copying terminaltables/base_table.py -> build/lib/terminaltables\n",
            "  copying terminaltables/build.py -> build/lib/terminaltables\n",
            "  copying terminaltables/width_and_alignment.py -> build/lib/terminaltables\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/github_table.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/other_tables.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/terminal_io.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/__init__.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/ascii_table.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/base_table.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/build.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/width_and_alignment.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing terminaltables.egg-info/PKG-INFO\n",
            "  writing dependency_links to terminaltables.egg-info/dependency_links.txt\n",
            "  writing top-level names to terminaltables.egg-info/top_level.txt\n",
            "  reading manifest file 'terminaltables.egg-info/SOURCES.txt'\n",
            "  writing manifest file 'terminaltables.egg-info/SOURCES.txt'\n",
            "  Copying terminaltables.egg-info to build/bdist.linux-x86_64/wheel/terminaltables-3.1.0-py3.7.egg-info\n",
            "  running install_scripts\n",
            "  creating build/bdist.linux-x86_64/wheel/terminaltables-3.1.0.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-0lfyi0fy/terminaltables-3.1.0-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'terminaltables/__init__.py'\n",
            "  adding 'terminaltables/ascii_table.py'\n",
            "  adding 'terminaltables/base_table.py'\n",
            "  adding 'terminaltables/build.py'\n",
            "  adding 'terminaltables/github_table.py'\n",
            "  adding 'terminaltables/other_tables.py'\n",
            "  adding 'terminaltables/terminal_io.py'\n",
            "  adding 'terminaltables/width_and_alignment.py'\n",
            "  adding 'terminaltables-3.1.0.dist-info/METADATA'\n",
            "  adding 'terminaltables-3.1.0.dist-info/WHEEL'\n",
            "  adding 'terminaltables-3.1.0.dist-info/top_level.txt'\n",
            "  adding 'terminaltables-3.1.0.dist-info/zip-safe'\n",
            "  adding 'terminaltables-3.1.0.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15354 sha256=710b0622a986604ea9f9835b3399f93f71889fd0e80c994b092d76f2e98d7efe\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/ad/c8/2d98360791161cd3db6daf6b5e730f34021fc9367d5879f497\n",
            "Successfully built terminaltables\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "  Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\n",
            "  Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\n",
            "  Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/terminaltables\n",
            "  sysconfig: /usr/include/python3.7m/terminaltables\n",
            "  Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\n",
            "  Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\n",
            "  Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\n",
            "\n",
            "  Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\n",
            "  Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\n",
            "  Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/mmdet\n",
            "  sysconfig: /usr/include/python3.7m/mmdet\n",
            "  Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\n",
            "  Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\n",
            "  Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\n",
            "  Running setup.py develop for mmdet\n",
            "    Running command /usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/content/mmdetection/setup.py'\"'\"'; __file__='\"'\"'/content/mmdetection/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps\n",
            "    running develop\n",
            "    running egg_info\n",
            "    creating mmdet.egg-info\n",
            "    writing mmdet.egg-info/PKG-INFO\n",
            "    writing dependency_links to mmdet.egg-info/dependency_links.txt\n",
            "    writing requirements to mmdet.egg-info/requires.txt\n",
            "    writing top-level names to mmdet.egg-info/top_level.txt\n",
            "    writing manifest file 'mmdet.egg-info/SOURCES.txt'\n",
            "    reading manifest template 'MANIFEST.in'\n",
            "    warning: no files found matching 'mmdet/VERSION'\n",
            "    warning: no files found matching 'mmdet/.mim/demo/*/*'\n",
            "    adding license file 'LICENSE'\n",
            "    writing manifest file 'mmdet.egg-info/SOURCES.txt'\n",
            "    running build_ext\n",
            "    Creating /usr/local/lib/python3.7/dist-packages/mmdet.egg-link (link to .)\n",
            "    Adding mmdet 2.17.0 to easy-install.pth file\n",
            "\n",
            "    Installed /content/mmdetection\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:370: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "      warnings.warn(msg.format('we could not find ninja.'))\n",
            "Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/include/python3.7/UNKNOWN\n",
            "sysconfig: /usr/include/python3.7m/UNKNOWN\n",
            "Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/bin\n",
            "sysconfig: /usr/bin\n",
            "Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local\n",
            "sysconfig: /usr\n",
            "Additional context:\n",
            "user = False\n",
            "home = None\n",
            "root = None\n",
            "prefix = None\n",
            "Successfully installed mmdet-2.17.0 terminaltables-3.1.0\n",
            "Removed build tracker: '/tmp/pip-req-tracker-7p_8xobk'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDlSsCUcDlr_"
      },
      "source": [
        "## コンフィグファイルの編集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ_ZoxbmPLGn"
      },
      "source": [
        "from mmcv import Config\n",
        "cfg = Config.fromfile('/content/mmdetection/configs/yolo/yolov3_d53_mstrain-608_273e_coco.py')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXx5P69_asuC",
        "outputId": "c920ab61-3038-496f-900f-d25f8a8c62a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnERVt6YrCD2"
      },
      "source": [
        "# MMdetectionの分類結果は、COCODatasetで定義された80分類に従って、表示されます。\n",
        "# 表示名を変更するには、以下のファイルの'cocodataset'の部分を編集してください。\n",
        "# /content/mmdetection/mmdet/datasets/coco.py\n",
        "# /content/mmdetection/mmdet/core/evaluation/class_names.py\n",
        "\n",
        "# 編集後にすでに編集ずみファイルを持っている場合は以下のように内容をコピーして置き換えてください。\n",
        "\n",
        "\n",
        "!cp \"コピーもとファイル\" \"/content/mmdetection/mmdet/datasets/coco.py\" -r\n",
        "!cp \"コピーもとファイル\" \"/content/mmdetection/mmdet/core/evaluation/class_names.py\" -r \n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl4npPTBEiUK",
        "outputId": "0725ebc7-90d5-491f-97a6-360a1f729960",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# コンフィグを変更する\n",
        "# yolov3\n",
        "\n",
        "#data_root = '画像データのルートフォルダ'\n",
        "data_root = '/content/'\n",
        "\n",
        "cfg.model.bbox_head.num_classes = '分類するクラス数'\n",
        "#cfg.num_class = 80\n",
        "cfg.data_root = data_root\n",
        "\n",
        "# trainデータの定義\n",
        "cfg.data.train.ann_file = '学習用のアノテーションファイル'\n",
        "cfg.data.train.img_prefix = data_root + '学習用画像データを保存したフォルダ'\n",
        "\n",
        "# valデータの定義\n",
        "cfg.data.val.ann_file = '検証用のアノテーションファイル'\n",
        "cfg.data.val.img_prefix = data_root + '検証用画像データを保存したフォルダ'\n",
        "\n",
        "\n",
        "# Let's have a look at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n",
        "\n",
        "\n",
        "# 編集したコンフィグをファイル出力\n",
        "cfg.dump('/content/yolo.py')\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config:\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
            "custom_hooks = [dict(type='NumClassCheckHook')]\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "model = dict(\n",
            "    type='YOLOV3',\n",
            "    backbone=dict(\n",
            "        type='Darknet',\n",
            "        depth=53,\n",
            "        out_indices=(3, 4, 5),\n",
            "        init_cfg=dict(type='Pretrained', checkpoint='open-mmlab://darknet53')),\n",
            "    neck=dict(\n",
            "        type='YOLOV3Neck',\n",
            "        num_scales=3,\n",
            "        in_channels=[1024, 512, 256],\n",
            "        out_channels=[512, 256, 128]),\n",
            "    bbox_head=dict(\n",
            "        type='YOLOV3Head',\n",
            "        num_classes=4,\n",
            "        in_channels=[512, 256, 128],\n",
            "        out_channels=[1024, 512, 256],\n",
            "        anchor_generator=dict(\n",
            "            type='YOLOAnchorGenerator',\n",
            "            base_sizes=[[(116, 90), (156, 198), (373, 326)],\n",
            "                        [(30, 61), (62, 45), (59, 119)],\n",
            "                        [(10, 13), (16, 30), (33, 23)]],\n",
            "            strides=[32, 16, 8]),\n",
            "        bbox_coder=dict(type='YOLOBBoxCoder'),\n",
            "        featmap_strides=[32, 16, 8],\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss',\n",
            "            use_sigmoid=True,\n",
            "            loss_weight=1.0,\n",
            "            reduction='sum'),\n",
            "        loss_conf=dict(\n",
            "            type='CrossEntropyLoss',\n",
            "            use_sigmoid=True,\n",
            "            loss_weight=1.0,\n",
            "            reduction='sum'),\n",
            "        loss_xy=dict(\n",
            "            type='CrossEntropyLoss',\n",
            "            use_sigmoid=True,\n",
            "            loss_weight=2.0,\n",
            "            reduction='sum'),\n",
            "        loss_wh=dict(type='MSELoss', loss_weight=2.0, reduction='sum')),\n",
            "    train_cfg=dict(\n",
            "        assigner=dict(\n",
            "            type='GridAssigner',\n",
            "            pos_iou_thr=0.5,\n",
            "            neg_iou_thr=0.5,\n",
            "            min_pos_iou=0)),\n",
            "    test_cfg=dict(\n",
            "        nms_pre=1000,\n",
            "        min_bbox_size=0,\n",
            "        score_thr=0.05,\n",
            "        conf_thr=0.005,\n",
            "        nms=dict(type='nms', iou_threshold=0.45),\n",
            "        max_per_img=100))\n",
            "dataset_type = 'CocoDataset'\n",
            "data_root = '/content/'\n",
            "img_norm_cfg = dict(mean=[0, 0, 0], std=[255.0, 255.0, 255.0], to_rgb=True)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile', to_float32=True),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(type='PhotoMetricDistortion'),\n",
            "    dict(type='Expand', mean=[0, 0, 0], to_rgb=True, ratio_range=(1, 2)),\n",
            "    dict(\n",
            "        type='MinIoURandomCrop',\n",
            "        min_ious=(0.4, 0.5, 0.6, 0.7, 0.8, 0.9),\n",
            "        min_crop_size=0.3),\n",
            "    dict(type='Resize', img_scale=[(320, 320), (608, 608)], keep_ratio=True),\n",
            "    dict(type='RandomFlip', flip_ratio=0.5),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[0, 0, 0],\n",
            "        std=[255.0, 255.0, 255.0],\n",
            "        to_rgb=True),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=(608, 608),\n",
            "        flip=False,\n",
            "        transforms=[\n",
            "            dict(type='Resize', keep_ratio=True),\n",
            "            dict(type='RandomFlip'),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[0, 0, 0],\n",
            "                std=[255.0, 255.0, 255.0],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=8,\n",
            "    workers_per_gpu=4,\n",
            "    train=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file='/content/drive/MyDrive/AIQUEST/annotation/train.json',\n",
            "        img_prefix='/content/train',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile', to_float32=True),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(type='PhotoMetricDistortion'),\n",
            "            dict(\n",
            "                type='Expand', mean=[0, 0, 0], to_rgb=True,\n",
            "                ratio_range=(1, 2)),\n",
            "            dict(\n",
            "                type='MinIoURandomCrop',\n",
            "                min_ious=(0.4, 0.5, 0.6, 0.7, 0.8, 0.9),\n",
            "                min_crop_size=0.3),\n",
            "            dict(\n",
            "                type='Resize',\n",
            "                img_scale=[(320, 320), (608, 608)],\n",
            "                keep_ratio=True),\n",
            "            dict(type='RandomFlip', flip_ratio=0.5),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[0, 0, 0],\n",
            "                std=[255.0, 255.0, 255.0],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file='/content/drive/MyDrive/AIQUEST/annotation/train.json',\n",
            "        img_prefix='/content/train',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(608, 608),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[0, 0, 0],\n",
            "                        std=[255.0, 255.0, 255.0],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file='data/coco/annotations/instances_val2017.json',\n",
            "        img_prefix='data/coco/val2017/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(608, 608),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[0, 0, 0],\n",
            "                        std=[255.0, 255.0, 255.0],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]))\n",
            "optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=2000,\n",
            "    warmup_ratio=0.1,\n",
            "    step=[218, 246])\n",
            "runner = dict(type='EpochBasedRunner', max_epochs=273)\n",
            "evaluation = dict(interval=1, metric=['bbox'])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hXq2KM6EaZv",
        "outputId": "196e9393-41a2-48f3-899b-65c3525830dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mkdir -p \"$HOME_PATH\"/work_train\n",
        "!python /content/mmdetection/tools/train.py \\\n",
        "    '/content/yolo.py' \\\n",
        "    --work-dir \"$HOME_PATH\"/work_train\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2021-10-28 01:31:15,405 - mmdet - INFO - Environment info:\n",
            "------------------------------------------------------------\n",
            "sys.platform: linux\n",
            "Python: 3.7.12 (default, Sep 10 2021, 00:21:48) [GCC 7.5.0]\n",
            "CUDA available: True\n",
            "GPU 0: Tesla P100-PCIE-16GB\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Build cuda_11.1.TC455_06.29190527_0\n",
            "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "PyTorch: 1.9.0+cu111\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.0.5\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
            "\n",
            "TorchVision: 0.10.0+cu111\n",
            "OpenCV: 4.1.2\n",
            "MMCV: 1.3.8\n",
            "MMCV Compiler: GCC 7.5\n",
            "MMCV CUDA Compiler: 11.1\n",
            "MMDetection: 2.17.0+\n",
            "------------------------------------------------------------\n",
            "\n",
            "2021-10-28 01:31:16,786 - mmdet - INFO - Distributed training: False\n",
            "2021-10-28 01:31:18,129 - mmdet - INFO - Config:\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
            "custom_hooks = [dict(type='NumClassCheckHook')]\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "model = dict(\n",
            "    type='YOLOV3',\n",
            "    backbone=dict(\n",
            "        type='Darknet',\n",
            "        depth=53,\n",
            "        out_indices=(3, 4, 5),\n",
            "        init_cfg=dict(type='Pretrained', checkpoint='open-mmlab://darknet53')),\n",
            "    neck=dict(\n",
            "        type='YOLOV3Neck',\n",
            "        num_scales=3,\n",
            "        in_channels=[1024, 512, 256],\n",
            "        out_channels=[512, 256, 128]),\n",
            "    bbox_head=dict(\n",
            "        type='YOLOV3Head',\n",
            "        num_classes=4,\n",
            "        in_channels=[512, 256, 128],\n",
            "        out_channels=[1024, 512, 256],\n",
            "        anchor_generator=dict(\n",
            "            type='YOLOAnchorGenerator',\n",
            "            base_sizes=[[(116, 90), (156, 198), (373, 326)],\n",
            "                        [(30, 61), (62, 45), (59, 119)],\n",
            "                        [(10, 13), (16, 30), (33, 23)]],\n",
            "            strides=[32, 16, 8]),\n",
            "        bbox_coder=dict(type='YOLOBBoxCoder'),\n",
            "        featmap_strides=[32, 16, 8],\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss',\n",
            "            use_sigmoid=True,\n",
            "            loss_weight=1.0,\n",
            "            reduction='sum'),\n",
            "        loss_conf=dict(\n",
            "            type='CrossEntropyLoss',\n",
            "            use_sigmoid=True,\n",
            "            loss_weight=1.0,\n",
            "            reduction='sum'),\n",
            "        loss_xy=dict(\n",
            "            type='CrossEntropyLoss',\n",
            "            use_sigmoid=True,\n",
            "            loss_weight=2.0,\n",
            "            reduction='sum'),\n",
            "        loss_wh=dict(type='MSELoss', loss_weight=2.0, reduction='sum')),\n",
            "    train_cfg=dict(\n",
            "        assigner=dict(\n",
            "            type='GridAssigner',\n",
            "            pos_iou_thr=0.5,\n",
            "            neg_iou_thr=0.5,\n",
            "            min_pos_iou=0)),\n",
            "    test_cfg=dict(\n",
            "        nms_pre=1000,\n",
            "        min_bbox_size=0,\n",
            "        score_thr=0.05,\n",
            "        conf_thr=0.005,\n",
            "        nms=dict(type='nms', iou_threshold=0.45),\n",
            "        max_per_img=100))\n",
            "dataset_type = 'CocoDataset'\n",
            "data_root = '/content/'\n",
            "img_norm_cfg = dict(mean=[0, 0, 0], std=[255.0, 255.0, 255.0], to_rgb=True)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile', to_float32=True),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(type='PhotoMetricDistortion'),\n",
            "    dict(type='Expand', mean=[0, 0, 0], to_rgb=True, ratio_range=(1, 2)),\n",
            "    dict(\n",
            "        type='MinIoURandomCrop',\n",
            "        min_ious=(0.4, 0.5, 0.6, 0.7, 0.8, 0.9),\n",
            "        min_crop_size=0.3),\n",
            "    dict(type='Resize', img_scale=[(320, 320), (608, 608)], keep_ratio=True),\n",
            "    dict(type='RandomFlip', flip_ratio=0.5),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[0, 0, 0],\n",
            "        std=[255.0, 255.0, 255.0],\n",
            "        to_rgb=True),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=(608, 608),\n",
            "        flip=False,\n",
            "        transforms=[\n",
            "            dict(type='Resize', keep_ratio=True),\n",
            "            dict(type='RandomFlip'),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[0, 0, 0],\n",
            "                std=[255.0, 255.0, 255.0],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=8,\n",
            "    workers_per_gpu=4,\n",
            "    train=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file='/content/drive/MyDrive/AIQUEST/annotation/train.json',\n",
            "        img_prefix='/content/train',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile', to_float32=True),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(type='PhotoMetricDistortion'),\n",
            "            dict(\n",
            "                type='Expand', mean=[0, 0, 0], to_rgb=True,\n",
            "                ratio_range=(1, 2)),\n",
            "            dict(\n",
            "                type='MinIoURandomCrop',\n",
            "                min_ious=(0.4, 0.5, 0.6, 0.7, 0.8, 0.9),\n",
            "                min_crop_size=0.3),\n",
            "            dict(\n",
            "                type='Resize',\n",
            "                img_scale=[(320, 320), (608, 608)],\n",
            "                keep_ratio=True),\n",
            "            dict(type='RandomFlip', flip_ratio=0.5),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[0, 0, 0],\n",
            "                std=[255.0, 255.0, 255.0],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file='/content/drive/MyDrive/AIQUEST/annotation/train.json',\n",
            "        img_prefix='/content/train',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(608, 608),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[0, 0, 0],\n",
            "                        std=[255.0, 255.0, 255.0],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file='data/coco/annotations/instances_val2017.json',\n",
            "        img_prefix='data/coco/val2017/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(608, 608),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[0, 0, 0],\n",
            "                        std=[255.0, 255.0, 255.0],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]))\n",
            "optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=2000,\n",
            "    warmup_ratio=0.1,\n",
            "    step=[218, 246])\n",
            "runner = dict(type='EpochBasedRunner', max_epochs=273)\n",
            "evaluation = dict(interval=1, metric=['bbox'])\n",
            "work_dir = '/content/work_train'\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "/content/mmdetection/mmdet/core/anchor/builder.py:17: UserWarning: ``build_anchor_generator`` would be deprecated soon, please use ``build_prior_generator`` \n",
            "  '``build_anchor_generator`` would be deprecated soon, please use '\n",
            "2021-10-28 01:31:19,123 - mmcv - INFO - load model from: open-mmlab://darknet53\n",
            "2021-10-28 01:31:19,123 - mmcv - INFO - Use load_from_openmmlab loader\n",
            "/content/mmdetection/mmdet/datasets/api_wrappers/coco_api.py:22: UserWarning: mmpycocotools is deprecated. Please install official pycocotools by \"pip install pycocotools\"\n",
            "  UserWarning)\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/content/mmdetection/mmdet/datasets/api_wrappers/coco_api.py:22: UserWarning: mmpycocotools is deprecated. Please install official pycocotools by \"pip install pycocotools\"\n",
            "  UserWarning)\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "2021-10-28 01:31:22,420 - mmdet - INFO - Start running, host: root@c5a6534bab1f, work_dir: /content/work_train\n",
            "2021-10-28 01:31:22,421 - mmdet - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(NORMAL      ) NumClassCheckHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(ABOVE_NORMAL) OptimizerHook                      \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) NumClassCheckHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "2021-10-28 01:31:22,421 - mmdet - INFO - workflow: [('train', 1)], max: 273 epochs\n",
            "/content/mmdetection/mmdet/core/anchor/anchor_generator.py:324: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
            "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
            "/content/mmdetection/mmdet/core/anchor/anchor_generator.py:361: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
            "  '``single_level_grid_anchors`` would be deprecated soon. '\n",
            "2021-10-28 01:32:57,688 - mmdet - INFO - Saving checkpoint at 1 epochs\n",
            "[>>] 289/289, 8.9 task/s, elapsed: 33s, ETA:     0s2021-10-28 01:33:32,610 - mmdet - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.14s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=8.63s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.44s).\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.019\n",
            "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.082\n",
            "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.002\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.019\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.066\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.066\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.066\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.066\n",
            "2021-10-28 01:33:41,956 - mmdet - INFO - Exp name: yolo.py\n",
            "2021-10-28 01:33:41,956 - mmdet - INFO - Epoch(val) [1][289]\tbbox_mAP: 0.0190, bbox_mAP_50: 0.0820, bbox_mAP_75: 0.0020, bbox_mAP_s: -1.0000, bbox_mAP_m: -1.0000, bbox_mAP_l: 0.0190, bbox_mAP_copypaste: 0.019 0.082 0.002 -1.000 -1.000 0.019\n",
            "2021-10-28 01:35:12,797 - mmdet - INFO - Saving checkpoint at 2 epochs\n",
            "[>>] 289/289, 8.9 task/s, elapsed: 33s, ETA:     0s2021-10-28 01:35:47,851 - mmdet - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.13s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=8.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.41s).\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.066\n",
            "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.196\n",
            "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.017\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.066\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.106\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.106\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.106\n",
            "2021-10-28 01:35:56,692 - mmdet - INFO - Exp name: yolo.py\n",
            "2021-10-28 01:35:56,693 - mmdet - INFO - Epoch(val) [2][289]\tbbox_mAP: 0.0660, bbox_mAP_50: 0.1960, bbox_mAP_75: 0.0170, bbox_mAP_s: -1.0000, bbox_mAP_m: -1.0000, bbox_mAP_l: 0.0660, bbox_mAP_copypaste: 0.066 0.196 0.017 -1.000 -1.000 0.066\n",
            "2021-10-28 01:37:30,187 - mmdet - INFO - Saving checkpoint at 3 epochs\n",
            "[>>] 289/289, 9.0 task/s, elapsed: 32s, ETA:     0s2021-10-28 01:38:04,631 - mmdet - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.13s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=7.60s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.42s).\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.094\n",
            "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.230\n",
            "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.045\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.094\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.133\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.133\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.133\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.133\n",
            "2021-10-28 01:38:12,906 - mmdet - INFO - Exp name: yolo.py\n",
            "2021-10-28 01:38:12,906 - mmdet - INFO - Epoch(val) [3][289]\tbbox_mAP: 0.0940, bbox_mAP_50: 0.2300, bbox_mAP_75: 0.0450, bbox_mAP_s: -1.0000, bbox_mAP_m: -1.0000, bbox_mAP_l: 0.0940, bbox_mAP_copypaste: 0.094 0.230 0.045 -1.000 -1.000 0.094\n",
            "2021-10-28 01:39:47,259 - mmdet - INFO - Saving checkpoint at 4 epochs\n",
            "[>>] 289/289, 9.0 task/s, elapsed: 32s, ETA:     0s2021-10-28 01:40:21,708 - mmdet - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=5.55s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.30s).\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.090\n",
            "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.237\n",
            "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.033\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.090\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.121\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.121\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.121\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.121\n",
            "2021-10-28 01:40:27,661 - mmdet - INFO - Exp name: yolo.py\n",
            "2021-10-28 01:40:27,661 - mmdet - INFO - Epoch(val) [4][289]\tbbox_mAP: 0.0900, bbox_mAP_50: 0.2370, bbox_mAP_75: 0.0330, bbox_mAP_s: -1.0000, bbox_mAP_m: -1.0000, bbox_mAP_l: 0.0900, bbox_mAP_copypaste: 0.090 0.237 0.033 -1.000 -1.000 0.090\n",
            "2021-10-28 01:41:59,347 - mmdet - INFO - Saving checkpoint at 5 epochs\n",
            "[> ] 154/289, 8.6 task/s, elapsed: 18s, ETA:    16sException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f7070c02290>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1296, in _shutdown_workers\n",
            "    self._mark_worker_as_unavailable(worker_id, shutdown=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1243, in _mark_worker_as_unavailable\n",
            "    q.put(None)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 89, in put\n",
            "    self._notempty.notify()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 352, in notify\n",
            "    waiter.release()\n",
            "KeyboardInterrupt: \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/mmdetection/tools/train.py\", line 189, in <module>\n",
            "    main()\n",
            "  File \"/content/mmdetection/tools/train.py\", line 185, in main\n",
            "    meta=meta)\n",
            "  File \"/content/mmdetection/mmdet/apis/train.py\", line 177, in train_detector\n",
            "    runner.run(data_loaders, cfg.workflow)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/runner/epoch_based_runner.py\", line 127, in run\n",
            "    epoch_runner(data_loaders[i], **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/runner/epoch_based_runner.py\", line 54, in train\n",
            "    self.call_hook('after_train_epoch')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/runner/base_runner.py\", line 307, in call_hook\n",
            "    getattr(hook, fn_name)(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/runner/hooks/evaluation.py\", line 220, in after_train_epoch\n",
            "    self._do_evaluate(runner)\n",
            "  File \"/content/mmdetection/mmdet/core/evaluation/eval_hooks.py\", line 18, in _do_evaluate\n",
            "    results = single_gpu_test(runner.model, self.dataloader, show=False)\n",
            "  File \"/content/mmdetection/mmdet/apis/test.py\", line 28, in single_gpu_test\n",
            "    result = model(return_loss=False, rescale=True, **data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/parallel/data_parallel.py\", line 42, in forward\n",
            "    return super().forward(*inputs, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 166, in forward\n",
            "    return self.module(*inputs[0], **kwargs[0])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/runner/fp16_utils.py\", line 97, in new_func\n",
            "    return old_func(*args, **kwargs)\n",
            "  File \"/content/mmdetection/mmdet/models/detectors/base.py\", line 174, in forward\n",
            "    return self.forward_test(img, img_metas, **kwargs)\n",
            "  File \"/content/mmdetection/mmdet/models/detectors/base.py\", line 147, in forward_test\n",
            "    return self.simple_test(imgs[0], img_metas[0], **kwargs)\n",
            "  File \"/content/mmdetection/mmdet/models/detectors/single_stage.py\", line 103, in simple_test\n",
            "    feat, img_metas, rescale=rescale)\n",
            "  File \"/content/mmdetection/mmdet/models/dense_heads/base_dense_head.py\", line 79, in simple_test\n",
            "    return self.simple_test_bboxes(feats, img_metas, rescale=rescale)\n",
            "  File \"/content/mmdetection/mmdet/models/dense_heads/dense_test_mixins.py\", line 36, in simple_test_bboxes\n",
            "    results_list = self.get_bboxes(*outs, img_metas, rescale=rescale)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/runner/fp16_utils.py\", line 184, in new_func\n",
            "    return old_func(*args, **kwargs)\n",
            "  File \"/content/mmdetection/mmdet/models/dense_heads/yolo_head.py\", line 246, in get_bboxes\n",
            "    flatten_strides.unsqueeze(-1))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/utils/parrots_jit.py\", line 21, in wrapper_inner\n",
            "    return func(*args, **kargs)\n",
            "  File \"/content/mmdetection/mmdet/core/bbox/coder/yolo_bbox_coder.py\", line 74, in decode\n",
            "    xy_centers = (bboxes[..., :2] + bboxes[..., 2:]) * 0.5 + (\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWpWKp8xDps0"
      },
      "source": [
        "## 学習結果の確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_9LdgUnsSF0n"
      },
      "source": [
        "from argparse import ArgumentParser\n",
        "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
        "model = init_detector(\"/content/yolo.py\", \"学習済みモデル\", device=device)\n",
        "result = inference_detector(model, \"予測結果を確認する画像のパス\")\n",
        "show_result_pyplot(model, \"予測結果を確認する画像のパス\", result, score_thr=0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m--0IpZEDt4_"
      },
      "source": [
        "## 予測タスクの実施"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4oCcVfMy0mN",
        "outputId": "850218ef-b031-4998-8dcc-9bc03903c6e5"
      },
      "source": [
        "from argparse import ArgumentParser\n",
        "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
        "import os\n",
        "\n",
        "testimage_path　 = \"テスト画像をおいたフォルダ\"\n",
        "\n",
        "imgaes = glob(testimage_path)\n",
        "\n",
        "# Specify the path to model config and checkpoint file\n",
        "config_file = '/content/drive/MyDrive/Detection/mmdetection/configs/htc/htc_without_semantic_r50_fpn_1x_coco.py'\n",
        "checkpoint_file = '学習済みモデルのパスを記載する'\n",
        "\n",
        "# build the model from a config file and a checkpoint file\n",
        "model = init_detector(config_file, checkpoint_file,device=device)\n",
        "\n",
        "\n",
        "\n",
        "bbox_dict1 = {}\n",
        "\n",
        "for image in images:\n",
        "    \n",
        "    if os.path.exists(image):\n",
        "\n",
        "        result = inference_detector(model, image)\n",
        "        \n",
        "        i = 0\n",
        "        result_segmentation = []\n",
        "\n",
        "        for i in range(6):\n",
        "            result_segmentation1 = []\n",
        "            tmp_bbox = []\n",
        "            if len(result[0][i]):\n",
        "                for j in range(len(result[0][i])):\n",
        "                    if len(result_segmentation1) == 0:\n",
        "                        contours = measure.find_contours(np.array(result[1][i][j]), 0.5)\n",
        "                        result_segmentation1.append([contours[0].tolist(),result[0][i][j][0:5].tolist()])\n",
        "                        tmp_bbox.append(result[0][i][j][0:4].tolist())\n",
        "\n",
        "                    else:\n",
        "                        if check_bbox(result[0][i][j][0:4].tolist(),tmp_bbox):\n",
        "                            contours = measure.find_contours(np.array(result[1][i][j]), 0.5)\n",
        "                            result_segmentation1.append([contours[0].tolist(),result[0][i][j][0:5].tolist()])\n",
        "                            tmp_bbox.append(result[0][i][j][0:4].tolist())                       \n",
        "\n",
        "\n",
        "                category = category_map[i+1]\n",
        "                bbox_dict = {\n",
        "                    category:result_segmentation1\n",
        "                }\n",
        "\n",
        "                if len(result_segmentation1):\n",
        "                    result_segmentation.append(bbox_dict)\n",
        "        \n",
        "        bbox_dict1[img] = result_segmentation\n",
        "\n",
        "\n",
        "with open('結果を出力するパス', 'w') as f:\n",
        "    json.dump(bbox_dict1, f, ensure_ascii=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Detection/mmdetection/mmdet/datasets/utils.py:68: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
            "  'data pipeline in your config file.', UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZYsbX7p5SOI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}