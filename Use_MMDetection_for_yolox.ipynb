{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Use_MMDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/saotomryo/Use_MMDetection/blob/main/Use_MMDetection.ipynb",
      "authorship_tag": "ABX9TyPnNkHUZDHt1hJfvdDA1PAF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saotomryo/Use_MMDetection/blob/main/Use_MMDetection_for_yolox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IPmHECyfHPp"
      },
      "source": [
        "import torch\n",
        "import json\n",
        "from skimage import measure\n",
        "import numpy as np\n",
        "print(torch.__version__)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"device = \", device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xdkNklHDWku"
      },
      "source": [
        "## 環境準備 MMCV MMDetectionのインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuhLiZC2ClOE"
      },
      "source": [
        "# MMCVのインストール（バージョンに合わせて修正してください。）\n",
        "\n",
        "!pip install https://download.openmmlab.com/mmcv/dist/cu113/torch1.10.0/mmcv_full-1.4.8-cp37-cp37m-manylinux1_x86_64.whl "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3WNFcX3PUcP"
      },
      "source": [
        "HOME_PATH = \"/content\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKdRG66riHGN"
      },
      "source": [
        "\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "%cd mmdetection\n",
        "!pip install -r requirements/build.txt\n",
        "!pip install \"git+https://github.com/open-mmlab/cocoapi.git#subdirectory=pycocotools\"\n",
        "!pip install -v -e .  # or \"python setup.py develop\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDlSsCUcDlr_"
      },
      "source": [
        "## コンフィグファイルの編集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXx5P69_asuC"
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MMdetectionの分類結果は、COCODatasetで定義された80分類に従って、表示されます。  \n",
        "表示名を変更するには、以下のファイルの'cocodataset'の部分を編集してください。  \n",
        "　/content/mmdetection/mmdet/datasets/coco.py  \n",
        "　/content/mmdetection/mmdet/core/evaluation/class_names.py"
      ],
      "metadata": {
        "id": "duiKuv6zkrpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# クラスのリストを持っている場合は、以下のように分類するクラスのリストを編集することができます。\n",
        "\n",
        "f = open('/content/mmdetection/mmdet/datasets/coco.py', 'r', encoding='UTF-8')\n",
        "\n",
        "data = f.read()\n",
        "f.close()\n",
        "\n",
        "from_index = data.find('CLASSES')\n",
        "end_index = data.find('toothbrush') + 13\n",
        "\n",
        "CLASSES_old = data[from_index:end_index]\n",
        "\n",
        "\n",
        "CLASSES_list = 'クラス分類するリストをここに入力してください。'\n",
        "num_classes = len(CLASSES_list)\n",
        "\n",
        "\n",
        "CLASSES_new = \"CLASSES = \" + str(tuple(CLASSES_list))\n",
        "\n",
        "data = data.replace(CLASSES_old,CLASSES_new)\n",
        "\n",
        "f = open('/content/mmdetection/mmdet/datasets/coco.py', 'w', encoding='UTF-8')\n",
        "\n",
        "f.write(data)"
      ],
      "metadata": {
        "id": "AcYO6Yrzk73U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/mmdetection/mmdet/core/evaluation/class_names.py', 'r', encoding='UTF-8')\n",
        "\n",
        "data = f.read()\n",
        "f.close()\n",
        "\n",
        "from_index = data.find(\"'person', 'bicycle',\")\n",
        "end_index = data.find(\"'toothbrush'\") + 12\n",
        "\n",
        "CLASSES_old = data[from_index:end_index]\n",
        "CLASSES_new = str(CLASSES_list)[1:-1]\n",
        "\n",
        "data = data.replace(CLASSES_old,CLASSES_new)\n",
        "\n",
        "f = open('/content/mmdetection/mmdet/core/evaluation/class_names.py', 'w', encoding='UTF-8')\n",
        "\n",
        "f.write(data)"
      ],
      "metadata": {
        "id": "1fiFltB7lfZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl4npPTBEiUK"
      },
      "source": [
        "from mmcv import Config\n",
        "cfg = Config.fromfile('/content/mmdetection/configs/yolox/yolox_tiny_8x8_300e_coco.py')\n",
        "\n",
        "# コンフィグを変更する\n",
        "# yolox\n",
        "\n",
        "#data_root = '画像データのルートフォルダ'\n",
        "data_root = '/content/'\n",
        "\n",
        "cfg.model.bbox_head.num_classes = num_classes #分類するクラス数\n",
        "#cfg.num_class = 80\n",
        "cfg.data_root = data_root\n",
        "\n",
        "# trainデータの定義\n",
        "cfg.data.train.dataset.ann_file = '学習用のアノテーションファイル'\n",
        "cfg.data.train.dataset.img_prefix = data_root + '学習用画像データを保存したフォルダ'\n",
        "\n",
        "# valデータの定義\n",
        "cfg.data.val.ann_file = '検証用のアノテーションファイル'\n",
        "cfg.data.val.img_prefix = data_root + '検証用画像データを保存したフォルダ'\n",
        "\n",
        "# バッチサイズ\n",
        "# cfg.data.samples_per_gpu = 2 #メモリエラーが出る場合は、バッチサイズを減らしてみてください。\n",
        "# cfg.data.workers_per_gpu = 2\n",
        "\n",
        "\n",
        "# Let's have a look at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n",
        "\n",
        "\n",
        "# 編集したコンフィグをファイル出力\n",
        "cfg.dump('/content/yolox_tiny_8x8_300e_coco.py'')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hXq2KM6EaZv"
      },
      "source": [
        "!mkdir -p \"$HOME_PATH\"/work_train\n",
        "!python /content/mmdetection/tools/train.py \\\n",
        "    '/content/yolox_tiny_8x8_300e_coco.py'' \\\n",
        "    --work-dir \"$HOME_PATH\"/work_train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWpWKp8xDps0"
      },
      "source": [
        "## 学習結果の確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_9LdgUnsSF0n"
      },
      "source": [
        "from argparse import ArgumentParser\n",
        "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
        "model = init_detector(\"/content/yolox_tiny_8x8_300e_coco.py'\", \"学習済みモデル\", device=device)\n",
        "result = inference_detector(model, \"予測結果を確認する画像のパス\")\n",
        "show_result_pyplot(model, \"予測結果を確認する画像のパス\", result, score_thr=0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m--0IpZEDt4_"
      },
      "source": [
        "## 予測タスクの実施"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4oCcVfMy0mN"
      },
      "source": [
        "from argparse import ArgumentParser\n",
        "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
        "import os\n",
        "\n",
        "testimage_path　 = \"テスト画像をおいたフォルダ\"\n",
        "\n",
        "imgaes = glob(testimage_path)\n",
        "\n",
        "# Specify the path to model config and checkpoint file\n",
        "config_file = '/content/yolox_tiny_8x8_300e_coco.py''\n",
        "checkpoint_file = '学習済みモデルのパスを記載する'\n",
        "\n",
        "# build the model from a config file and a checkpoint file\n",
        "model = init_detector(config_file, checkpoint_file,device=device)\n",
        "\n",
        "\n",
        "\n",
        "bbox_dict1 = {}\n",
        "\n",
        "for image in images:\n",
        "    \n",
        "    if os.path.exists(image):\n",
        "\n",
        "        result = inference_detector(model, image)\n",
        "        \n",
        "        i = 0\n",
        "        result_segmentation = []\n",
        "\n",
        "        for i in range(6):\n",
        "            result_segmentation1 = []\n",
        "            tmp_bbox = []\n",
        "            if len(result[0][i]):\n",
        "                for j in range(len(result[0][i])):\n",
        "                    if len(result_segmentation1) == 0:\n",
        "                        contours = measure.find_contours(np.array(result[1][i][j]), 0.5)\n",
        "                        result_segmentation1.append([contours[0].tolist(),result[0][i][j][0:5].tolist()])\n",
        "                        tmp_bbox.append(result[0][i][j][0:4].tolist())\n",
        "\n",
        "                    else:\n",
        "                        if check_bbox(result[0][i][j][0:4].tolist(),tmp_bbox):\n",
        "                            contours = measure.find_contours(np.array(result[1][i][j]), 0.5)\n",
        "                            result_segmentation1.append([contours[0].tolist(),result[0][i][j][0:5].tolist()])\n",
        "                            tmp_bbox.append(result[0][i][j][0:4].tolist())                       \n",
        "\n",
        "\n",
        "                category = category_map[i+1]\n",
        "                bbox_dict = {\n",
        "                    category:result_segmentation1\n",
        "                }\n",
        "\n",
        "                if len(result_segmentation1):\n",
        "                    result_segmentation.append(bbox_dict)\n",
        "        \n",
        "        bbox_dict1[img] = result_segmentation\n",
        "\n",
        "\n",
        "with open('結果を出力するパス', 'w') as f:\n",
        "    json.dump(bbox_dict1, f, ensure_ascii=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZYsbX7p5SOI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}